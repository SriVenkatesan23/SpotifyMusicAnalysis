{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songDf = pd.read_csv(\"songData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'acousticness', u'analysis_url',\n",
       "       u'danceability', u'duration_ms', u'energy', u'id', u'instrumentalness',\n",
       "       u'key', u'liveness', u'loudness', u'mode', u'speechiness', u'tempo',\n",
       "       u'time_signature', u'track_href', u'type', u'uri', u'valence', u'genre',\n",
       "       u'artist', u'date', u'name', u'popularity', u'lyric'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songDf = songDf.drop(['Unnamed: 0', 'Unnamed: 0.1', 'analysis_url', 'id','track_href','type', 'uri', 'artist', 'date'\n",
    "                     ,'name', 'popularity', 'lyric'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songDf = songDf.sample(frac = 1, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songDf = pd.get_dummies(songDf, columns=['key','time_signature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'acousticness', u'danceability', u'duration_ms', u'energy',\n",
       "       u'instrumentalness', u'liveness', u'loudness', u'mode', u'speechiness',\n",
       "       u'tempo', u'valence', u'genre', u'key_0', u'key_1', u'key_2', u'key_3',\n",
       "       u'key_4', u'key_5', u'key_6', u'key_7', u'key_8', u'key_9', u'key_10',\n",
       "       u'key_11', u'time_signature_0', u'time_signature_1',\n",
       "       u'time_signature_3', u'time_signature_4', u'time_signature_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = songDf.iloc[0:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = songDf.iloc[8000:11240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLabels = train['genre'].astype('category')\n",
    "testLabels = test['genre'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop(['genre'], axis = 1)\n",
    "test = test.drop(['genre'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocessing.scale(train)\n",
    "test = preprocessing.scale(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fold(model, trainData, labels, n_folds, n_class):\n",
    "    accs = 0\n",
    "    precs = np.array([0]*n_class)\n",
    "    recalls = np.array([0]*n_class)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for x in range(0,n_folds):\n",
    "        start = x * len(trainData)/n_folds\n",
    "        end = (x+1) * len(trainData)/n_folds\n",
    "        index = range(0,start) + range(end,len(trainData))\n",
    "        fit = model.fit(X = trainData[index], y = labels.iloc[index] )\n",
    "        score = fit.score(trainData[start:end], labels.iloc[start:end])\n",
    "        accs = accs + score\n",
    "        predictions = fit.predict(trainData[start:end])\n",
    "        true = labels.iloc[start:end]\n",
    "        prf = precision_recall_fscore_support(y_true = true, y_pred = predictions)\n",
    "        precs = precs + prf[0]\n",
    "        recalls = (recalls + prf[1])\n",
    "    \n",
    "    accs = accs/float(n_folds)\n",
    "    precs = precs/float(n_folds)\n",
    "    recalls = recalls/float(n_folds)\n",
    "    \n",
    "    return((accs, precs, recalls, fit.classes_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### multinomial logistic regression with balanced weights\n",
    "\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\" , class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67225000000000001,\n",
       " array([ 0.43888155,  0.32304214,  0.84701375,  0.52970877,  0.84692475,\n",
       "         0.2606726 ,  0.87934448,  0.63538098]),\n",
       " array([ 0.56176853,  0.72665692,  0.88365781,  0.68380031,  0.83375188,\n",
       "         0.50002792,  0.70648906,  0.3950369 ]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'], dtype=object))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrAccs = fold(lr, train, trainLabels, 4, 8)\n",
    "lrAccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### multinomial logistic regression without balanced weights\n",
    "\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72450000000000003,\n",
       " array([ 0.53619479,  0.48578935,  0.9048136 ,  0.57673724,  0.82939207,\n",
       "         0.42559524,  0.78219848,  0.5694021 ]),\n",
       " array([ 0.44272304,  0.18576998,  0.83542707,  0.62041421,  0.87131811,\n",
       "         0.06739966,  0.88875885,  0.66232911]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'], dtype=object))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrAccs = fold(lr, train, trainLabels, 4, 8)\n",
    "lrAccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### KNN using default of 5 neighbours\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65449999999999997,\n",
       " array([ 0.42678646,  0.31848419,  0.82962018,  0.57592482,  0.74955692,\n",
       "         0.24173675,  0.76680284,  0.54543389]),\n",
       " array([ 0.37670438,  0.40645712,  0.80833525,  0.54497908,  0.81453481,\n",
       "         0.18030279,  0.77747235,  0.49675576]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'], dtype=object))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnAccs = fold(knn, train, trainLabels, 4, 8)\n",
    "knnAccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_depth = 8, class_weight = \"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74012500000000003,\n",
       " array([ 0.4507556 ,  0.44976838,  0.91222538,  0.54324125,  0.87425009,\n",
       "         0.34000982,  0.86783683,  0.72433161]),\n",
       " array([ 0.61602249,  0.82838694,  0.93874308,  0.67126889,  0.88320856,\n",
       "         0.42540423,  0.81933855,  0.48595493]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'], dtype=object))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfAccs = fold(rf, train, trainLabels, 4, 8)\n",
    "rfAccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.45263800e-01,   1.33974868e-01,   8.32726935e-02,\n",
       "         1.07763684e-01,   1.17891742e-01,   4.03268048e-02,\n",
       "         6.31114198e-02,   9.63086076e-03,   1.06034649e-01,\n",
       "         5.69270281e-02,   7.75708739e-02,   4.29383022e-03,\n",
       "         5.75287580e-03,   4.88668739e-03,   2.29640577e-03,\n",
       "         3.97694907e-03,   3.85665771e-03,   3.66517526e-03,\n",
       "         4.83100028e-03,   3.66754787e-03,   4.46174482e-03,\n",
       "         3.35122175e-03,   3.75124340e-03,   6.29198652e-05,\n",
       "         4.38015672e-04,   3.76157991e-03,   4.11588696e-03,\n",
       "         1.06183433e-03])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train, trainLabels).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'acousticness', u'danceability', u'duration_ms', u'energy',\n",
       "       u'instrumentalness', u'liveness', u'loudness', u'mode', u'speechiness',\n",
       "       u'tempo', u'valence', u'genre', u'key_0', u'key_1', u'key_2', u'key_3',\n",
       "       u'key_4', u'key_5', u'key_6', u'key_7', u'key_8', u'key_9', u'key_10',\n",
       "       u'key_11', u'time_signature_0', u'time_signature_1',\n",
       "       u'time_signature_3', u'time_signature_4', u'time_signature_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68037499999999995,\n",
       " array([ 0.40712671,  0.33140727,  0.86707079,  0.52556799,  0.87265146,\n",
       "         0.27743175,  0.88437632,  0.63944702]),\n",
       " array([ 0.56199191,  0.72266082,  0.89539911,  0.66513737,  0.81083581,\n",
       "         0.51680307,  0.710707  ,  0.45015157]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'], dtype=object))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVM one vs all\n",
    "\n",
    "sv = SVC(kernel = \"rbf\", class_weight = \"balanced\")\n",
    "fold(sv, train, trainLabels, 4, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Gradient Boosting Classifier \n",
    "\n",
    "gbc = GradientBoostingClassifier(loss = \"deviance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77712499999999995,\n",
       " array([ 0.57148811,  0.67859964,  0.95105359,  0.58169712,  0.88027143,\n",
       "         0.45020212,  0.83250251,  0.65741802]),\n",
       " array([ 0.44694969,  0.56423002,  0.93714504,  0.61737358,  0.87503663,\n",
       "         0.2279888 ,  0.90732538,  0.7189776 ]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'], dtype=object))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold(gbc, train, trainLabels, 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.70399999999999996,\n",
       " array([ 0.53033911,  0.        ,  0.89739798,  0.54859271,  0.79801235,\n",
       "         0.        ,  0.76220407,  0.53451418]),\n",
       " array([ 0.3376839 ,  0.        ,  0.76544486,  0.61382595,  0.87259103,\n",
       "         0.        ,  0.89775932,  0.66443158]),\n",
       " array(['blues', 'country', 'electric', 'jazz', 'metal', 'pop', 'rap',\n",
       "        'rock'],\n",
       "       dtype='|S8'))"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlnn = MLPClassifier(solver = \"sgd\", activation = \"logistic\")\n",
    "fold(mlnn, train, trainLabels, 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####Now Going to add lyrics data [will have to censor certain songs bc no lyrics] - need to do imports\n",
    "import collections, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Creating Vector Matrix for our words\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "songDf = pd.read_csv(\"songData.csv\")\n",
    "emptyList = (pd.isnull(songDf['lyric']))\n",
    "notEmptyList = list(~np.array(emptyList))\n",
    "notEmptyIndex = np.where(notEmptyList)[0]\n",
    "songDf_lyrics = songDf.iloc[notEmptyIndex]\n",
    "\n",
    "data_corpus = songDf['lyric'][notEmptyIndex]\n",
    "X = vectorizer.fit_transform(data_corpus) \n",
    "tfidfTransform = TfidfTransformer()\n",
    "tfidfValues = tfidfTransform.fit_transform(X)\n",
    "tfidfMatrix = pd.DataFrame(tfidfValues.toarray())\n",
    "tfidfMatrix.columns = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rapScore = (tfidfMatrix['nigga']+tfidfMatrix['niggas']+tfidfMatrix['money']+tfidfMatrix['shit']+tfidfMatrix['fuck']\n",
    " +tfidfMatrix['bitch']+tfidfMatrix['ain']+tfidfMatrix['hook']+tfidfMatrix['verse']) * 10\n",
    "\n",
    "metalScore = (tfidfMatrix['life']+tfidfMatrix['hell']+tfidfMatrix['death']+tfidfMatrix['blood']+tfidfMatrix['world']\n",
    "              +tfidfMatrix['dead']+tfidfMatrix['god']+tfidfMatrix['flesh']+tfidfMatrix['fear'] \n",
    "              +tfidfMatrix['god']+tfidfMatrix['pain']+tfidfMatrix['die']+tfidfMatrix['eyes']\n",
    "              +tfidfMatrix['shall']+tfidfMatrix['end']) * 10\n",
    "\n",
    "popScore = (tfidfMatrix['oh'] + tfidfMatrix['chorus']+tfidfMatrix['love']) * 10\n",
    "\n",
    "rockScore = (tfidfMatrix['bridge'] + tfidfMatrix['love']+tfidfMatrix['cause']) * 10\n",
    "\n",
    "countryScore = (tfidfMatrix['country']+tfidfMatrix['road'] + tfidfMatrix['chorus'] ) * 10\n",
    "\n",
    "jazzScore = (tfidfMatrix['instrumental']+tfidfMatrix['jazz'] ) * 10\n",
    "\n",
    "bluesScore = (tfidfMatrix['blues']+tfidfMatrix['instrumental'] ) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Remove useless columns\n",
    "songDf_lyrics = songDf_lyrics.drop(['Unnamed: 0', 'Unnamed: 0.1', 'analysis_url', 'id','track_href','type', 'uri', 'artist', 'date'\n",
    "                     ,'name', 'popularity', 'lyric'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "songDf_lyrics.columns = ['acousticness_1', 'danceability_1', 'duration_ms_1', 'energy_1', 'instrumentalness_1', 'key_1',\n",
    "                        'liveness_1', 'loudness_1', 'mode_1', 'speechiness_1', 'tempo_1', 'time_signature_1', 'valence_1', \n",
    "                         'genre_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Concatenate Dataframes\n",
    "scoreData = pd.concat([songDf_lyrics.reset_index(), rapScore, metalScore, popScore, rockScore, countryScore, jazzScore, bluesScore], axis=1)\n",
    "lyricsData = pd.concat([songDf_lyrics.reset_index(), tfidfMatrix], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreData;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricsData = lyricsData.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricsData = lyricsData.drop(['level_0', 'index'], axis = 1)\n",
    "scoreData = scoreData.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyricsData = lyricsData.sample(frac = 1, replace = False)\n",
    "lyricsData = pd.get_dummies(lyricsData, columns=['key_1','time_signature_1'])\n",
    "\n",
    "scoreData = scoreData.sample(frac = 1, replace = False)\n",
    "scoreData = pd.get_dummies(scoreData, columns=['key_1','time_signature_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([5599, 5600, 5601], dtype='int64')"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elecIndex = lyricsData[lyricsData.genre_1 == \"electric\"].index\n",
    "elecIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lyricsData = lyricsData.drop([5601, 5599, 5600], axis = 0)\n",
    "scoreData = scoreData.drop([5601, 5599, 5600], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyric = lyricsData.iloc[0:6000]\n",
    "test_lyric = lyricsData.iloc[6000:8120]\n",
    "\n",
    "train_score = scoreData.iloc[0:6000]\n",
    "test_score = scoreData.iloc[6000:8120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainLyric_label = train_lyric.genre_1\n",
    "testLyric_label = test_lyric.genre_1\n",
    "\n",
    "trainScore_label = train_score.genre_1\n",
    "testScore_label = test_score.genre_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lyric = train_lyric.drop(['genre_1'], axis = 1)\n",
    "test_lyric = test_lyric.drop(['genre_1'], axis = 1)\n",
    "\n",
    "train_score = train_score.drop(['genre_1'], axis = 1)\n",
    "test_score = test_score.drop(['genre_1'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lyric = preprocessing.scale(train_lyric)\n",
    "test_lyric = preprocessing.scale(test_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_score = preprocessing.scale(train_score)\n",
    "test_score = preprocessing.scale(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72116666666666662,\n",
       " array([ 0.23025794,  0.40768899,  0.53622943,  0.88116222,  0.41108753,\n",
       "         0.93917616,  0.64920771]),\n",
       " array([ 0.53541667,  0.71610493,  0.80489795,  0.85551775,  0.64962979,\n",
       "         0.83919533,  0.42899458]),\n",
       " array(['blues', 'country', 'jazz', 'metal', 'pop', 'rap', 'rock'], dtype=object))"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### multinomial logistic regression with balanced weights\n",
    "\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\", class_weight = \"balanced\" )\n",
    "\n",
    "\n",
    "\n",
    "lrAccs = fold(lr, train_score, trainScore_label, 3, 7)\n",
    "lrAccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.67149999999999999,\n",
       " array([ 0.18511905,  0.33114289,  0.60135647,  0.77703879,  0.29857181,\n",
       "         0.83322025,  0.54264796]),\n",
       " array([ 0.07127193,  0.41733513,  0.60642207,  0.84133105,  0.2940199 ,\n",
       "         0.82704336,  0.48224509]),\n",
       " array(['blues', 'country', 'jazz', 'metal', 'pop', 'rap', 'rock'], dtype=object))"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### KNN using default of 5 neighbours\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knnAccs = fold(knn, train_score, trainScore_label, 3, 7)\n",
    "knnAccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78666666666666674,\n",
       " array([ 0.32775083,  0.53391354,  0.63365893,  0.91388297,  0.49153261,\n",
       "         0.90756851,  0.73541965]),\n",
       " array([ 0.35153509,  0.77301427,  0.86367674,  0.88608332,  0.64483363,\n",
       "         0.89407001,  0.59269133]),\n",
       " array(['blues', 'country', 'jazz', 'metal', 'pop', 'rap', 'rock'], dtype=object))"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_depth = 8, class_weight = \"balanced\")\n",
    "\n",
    "rfAccs = fold(rf, train_score, trainScore_label, 3, 7)\n",
    "rfAccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.72616666666666674,\n",
       " array([ 0.20982692,  0.39525849,  0.56744317,  0.89713117,  0.39939054,\n",
       "         0.93297109,  0.64865806]),\n",
       " array([ 0.41239035,  0.67103977,  0.72345548,  0.83899297,  0.59095875,\n",
       "         0.84203647,  0.5150547 ]),\n",
       " array(['blues', 'country', 'jazz', 'metal', 'pop', 'rap', 'rock'], dtype=object))"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVM one vs all\n",
    "\n",
    "sv = SVC(kernel = \"rbf\", class_weight = \"balanced\")\n",
    "fold(sv, train_score, trainScore_label, 3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.81016666666666659,\n",
       " array([ 0.44731109,  0.70283438,  0.75585006,  0.89915462,  0.58075489,\n",
       "         0.89730239,  0.68713314]),\n",
       " array([ 0.21600877,  0.57471632,  0.76320174,  0.89823148,  0.45910921,\n",
       "         0.93142736,  0.75238143]),\n",
       " array(['blues', 'country', 'jazz', 'metal', 'pop', 'rap', 'rock'], dtype=object))"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Gradient Boosting Classifier \n",
    "\n",
    "gbc = GradientBoostingClassifier(loss = \"deviance\", max_depth = 3)\n",
    "fold(gbc, train_score, trainScore_label, 3, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seeing what happens on testing Data\n",
    "\n",
    "### Just Spotify Data using RandomForest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_depth = 8, class_weight = \"balanced\")\n",
    "rfFit = rf.fit(train, trainLabels)\n",
    "\n",
    "\n",
    "#### Just Spotify Data using GBC\n",
    "gbc = GradientBoostingClassifier(loss = \"deviance\")\n",
    "gbcFit = gbc.fit(train, trainLabels)\n",
    "\n",
    "##### Just Spotify Data using Logisitc Regression\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\", class_weight = \"balanced\")\n",
    "lrFit = lr.fit(train, trainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7260909935\n",
      "0.769421231817\n",
      "0.673166202414\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "print(rfFit.score(test, testLabels))\n",
    "print(gbcFit.score(test, testLabels))\n",
    "print(lrFit.score(test, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45070423  0.38110749  0.90647482  0.51960784  0.88126362  0.34433962\n",
      "  0.86431479  0.66512702]\n",
      "[ 0.55445545  0.57541899  0.98360656  0.56578947  0.85876289  0.58064516\n",
      "  0.80089989  0.66246057]\n",
      "[ 0.3902439   0.32716049  0.79139073  0.54761905  0.87301587  0.2875\n",
      "  0.89090909  0.60470588]\n",
      "['blues' 'country' 'electric' 'jazz' 'metal' 'pop' 'rap' 'rock']\n"
     ]
    }
   ],
   "source": [
    "###Precision\n",
    "print(precision_recall_fscore_support(y_true = testLabels, y_pred = rfFit.predict(test))[0])\n",
    "print(precision_recall_fscore_support(y_true = testLabels, y_pred = gbcFit.predict(test))[0])\n",
    "print(precision_recall_fscore_support(y_true = testLabels, y_pred = lrFit.predict(test))[0])\n",
    "print(rfFit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.41558442  0.83571429  0.92647059  0.77372263  0.87082885  0.4591195\n",
      "  0.82512953  0.43113772]\n",
      "[ 0.36363636  0.73571429  0.88235294  0.62773723  0.89666308  0.22641509\n",
      "  0.92227979  0.62874251]\n",
      "[ 0.51948052  0.75714286  0.87867647  0.67153285  0.82884822  0.57861635\n",
      "  0.69818653  0.38473054]\n",
      "['blues' 'country' 'electric' 'jazz' 'metal' 'pop' 'rap' 'rock']\n"
     ]
    }
   ],
   "source": [
    "### Recall\n",
    "print(precision_recall_fscore_support(y_true = testLabels, y_pred = rfFit.predict(test))[1])\n",
    "print(precision_recall_fscore_support(y_true = testLabels, y_pred = gbcFit.predict(test))[1])\n",
    "print(precision_recall_fscore_support(y_true = testLabels, y_pred = lrFit.predict(test))[1])\n",
    "print(rfFit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55,   3,   0,  44,   2,   2,  13,  35],\n",
       "       [  0, 103,   0,   0,   0,   2,   8,  27],\n",
       "       [  0,   0, 240,   0,  16,   0,  10,   6],\n",
       "       [ 30,   1,   0,  86,   0,   1,  10,   9],\n",
       "       [  0,   2,   1,   0, 834,   0,   4,  88],\n",
       "       [  2,  17,   0,   5,   0,  36,  86,  13],\n",
       "       [  2,   5,   0,   3,   3,  12, 712,  35],\n",
       "       [ 10,  48,   3,  15, 114,  10,  46, 422]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testLabels, gbcFit.predict(test), gbcFit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seeing what happens on testing Data\n",
    "\n",
    "### Lyric Score Data using RandomForest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_depth = 8, class_weight = \"balanced\")\n",
    "rfFit = rf.fit(train_score, trainScore_label)\n",
    "\n",
    "\n",
    "#### Lyric Score Data using GBC\n",
    "gbc = GradientBoostingClassifier(loss = \"deviance\")\n",
    "gbcFit = gbc.fit(train_score, trainScore_label)\n",
    "\n",
    "##### Lyric Score Data using Logisitc Regression\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\", class_weight = \"balanced\")\n",
    "lrFit = lr.fit(train_score, trainScore_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71138403401\n",
      "0.803967879074\n",
      "0.744922059518\n"
     ]
    }
   ],
   "source": [
    "## Accuracy\n",
    "print(rfFit.score(test_score, testScore_label))\n",
    "print(gbcFit.score(test_score, testScore_label))\n",
    "print(lrFit.score(test_score, testScore_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3220339   0.31481481  0.58510638  0.9625      0.42328042  0.87021631\n",
      "  0.59593023]\n",
      "[ 0.57142857  0.62790698  0.7         0.95341098  0.54455446  0.86990596\n",
      "  0.67684022]\n",
      "[ 0.3047619   0.37        0.58762887  0.91137371  0.38190955  0.94528302\n",
      "  0.71197411]\n",
      "['blues' 'country' 'jazz' 'metal' 'pop' 'rap' 'rock']\n"
     ]
    }
   ],
   "source": [
    "###Precision\n",
    "print(precision_recall_fscore_support(y_true = testScore_label, y_pred = rfFit.predict(test_score))[0])\n",
    "print(precision_recall_fscore_support(y_true = testScore_label, y_pred = gbcFit.predict(test_score))[0])\n",
    "print(precision_recall_fscore_support(y_true = testScore_label, y_pred = lrFit.predict(test_score))[0])\n",
    "print(rfFit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.38        0.86734694  0.90163934  0.77110157  0.68376068  0.8760469\n",
      "  0.41414141]\n",
      "[ 0.24        0.82653061  0.80327869  0.81974249  0.47008547  0.92964824\n",
      "  0.76161616]\n",
      "[ 0.64        0.75510204  0.93442623  0.88268956  0.64957265  0.83919598\n",
      "  0.44444444]\n",
      "['blues' 'country' 'jazz' 'metal' 'pop' 'rap' 'rock']\n"
     ]
    }
   ],
   "source": [
    "###Recall\n",
    "print(precision_recall_fscore_support(y_true = testScore_label, y_pred = rfFit.predict(test_score))[1])\n",
    "print(precision_recall_fscore_support(y_true = testScore_label, y_pred = gbcFit.predict(test_score))[1])\n",
    "print(precision_recall_fscore_support(y_true = testScore_label, y_pred = lrFit.predict(test_score))[1])\n",
    "print(rfFit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12,   0,   7,   0,   0,   7,  24],\n",
       "       [  0,  81,   0,   0,   6,   2,   9],\n",
       "       [  3,   1,  49,   0,   3,   3,   2],\n",
       "       [  0,   2,   0, 573,   1,   5, 118],\n",
       "       [  0,   8,   2,   0,  55,  36,  16],\n",
       "       [  1,   2,   2,   0,  26, 555,  11],\n",
       "       [  5,  35,  10,  28,  10,  30, 377]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testScore_label, gbcFit.predict(test_score), gbcFit.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Trying Principal Components Analysis\n",
    "\n",
    "pca = PCA(n_components = 2).fit_transform(train_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df['genre'] = trainLyric_label.reset_index()['genre_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.columns = ['x','y','genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.to_csv(\"pcaFile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trying Principal Components Analysis with 75 components\n",
    "\n",
    "\n",
    "train_lyric_notValid = train_lyric[0:4000]\n",
    "notValid_label = trainLyric_label[0:4000]\n",
    "train_lyric_valid = train_lyric[4000:6005]\n",
    "valid_label = trainLyric_label[4000:6005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_notValid = PCA(n_components = 75).fit_transform(train_lyric_notValid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_Valid = PCA(n_components = 75).fit_transform(np.concatenate((train_lyric_notValid, train_lyric_valid), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_notValid = preprocessing.scale(pca_notValid)\n",
    "pca_Valid = preprocessing.scale(pca_Valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_Valid = pca_Valid[4000:6005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.219"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Trying some models\n",
    "\n",
    "### First Multinomial Logistic Regression\n",
    "lr = LogisticRegression(multi_class = \"multinomial\", solver = \"saga\", class_weight = \"balanced\")\n",
    "fit = lr.fit(pca_notValid, notValid_label)\n",
    "\n",
    "fit.score(pca_Valid, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pca_Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
